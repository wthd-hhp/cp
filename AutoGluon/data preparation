import rdkit
import pandas as pd
import numpy as np
from collections import Counter

from rdkit import Chem
from rdkit.Chem import Descriptors
from rdkit.ML.Descriptors import MoleculeDescriptors
from mordred import Calculator, descriptors
from warnings import simplefilter
simplefilter(action='ignore', category=FutureWarning)

experimental_data = pd.read_excel('298.15k下的气态热容.xlsx',index_col=0)
experimental_data

import os
folder_path = 'SDFdata/'
files = []
for filename in os.listdir(folder_path):
    if os.path.isfile(os.path.join(folder_path, filename)):
        files.append(filename)
print(files)

# 比较Rdkit与Mordred分子描述符 
calc = Calculator(descriptors, ignore_3D=True)
Mordred_description = []
Rdkit_description = [x[0] for x in Descriptors._descList]
for i in calc.descriptors:
    Mordred_description.append(i.__str__())
for i in Mordred_description:
    if i in Rdkit_description:
        Rdkit_description.remove(i)
        
Molecular_descriptor = []

descriptor_calculator = MoleculeDescriptors.MolecularDescriptorCalculator(Rdkit_description)
j =0
for i in mols:
    Calculator_descript = pd.DataFrame(calc.pandas([i]))
    rdkit_descriptors = pd.DataFrame([descriptor_calculator.CalcDescriptors(i)],columns=Rdkit_description)
    Calculator_descript = Calculator_descript.join(rdkit_descriptors)
    Molecular_descriptor.append(Calculator_descript)
    j+=1
    print(j)
    
a = Molecular_descriptor[0]
for i in Molecular_descriptor[1:]:
    a = a.append(i)
a = a.reset_index(drop=True)
# 删除计算失败的值
a = a.drop(labels=a.dtypes[a.dtypes == "object"].index,axis=1)
a

# 将分子描述符与预测值结合
NAME = [x.replace("-3d","").replace(".sdf","").replace("-2d", "").replace(".mol","") for x in files]
a.insert(0,"NAME",NAME)

import math

# lef_series_index = [x.replace("\xa0","") for x in experimental_data["3dSD"].values]
y_series_index = []
for x in experimental_data["CAS"].values:
    if type(x) == str:
        y_series_index.append(x.replace("\xa0",""))
    else:
        y_series_index.append(x)
        
for i in range(len(y_series_index)):
    if type(y_series_index[i])!=str:
        y_series_index[i] = y_series_index[i-1]
y_series_value = [float(x) for x in experimental_data["Cp (J/mol.K)"].values] 
y_series = pd.Series(y_series_value)
y_series.index = y_series_index
y_series = pd.DataFrame(y_series)
y_series

temp_data = pd.DataFrame()
final_data = pd.DataFrame()
for i in a['NAME'].unique():
    # 筛选出与 a 中 NAME 列相等的行
    temp_data = a[a["NAME"] == i].copy()
    
    # 从 y_series 获取对应的 Cp 值
    cp_value = y_series[y_series.index == i].values
    
    # 确保 cp_value 的长度与 temp_data 的行数相匹配
    if len(cp_value) > 1:  # 如果有多个 Cp 值
        # 选择第一个 Cp 值或进行其他处理
        cp_value = cp_value[0]
    elif len(cp_value) == 0:  # 如果没有 Cp 值
        cp_value = np.nan  # 使用 NaN 作为默认值
    
    # 插入 Cp 列，确保长度匹配
    temp_data.insert(1, "Cp", cp_value)
    
    # 将 temp_data 添加到 final_data
    final_data = final_data.append(temp_data, ignore_index=True)

# 删除0值和空值
consolidated_data  = final_data.dropna(axis=1,how='any')
print(consolidated_data.shape)
data0=(consolidated_data==0).sum(axis = 0)
number0 = data0[data0>=final_data.shape[0]/2]
number0.index
consolidated_data = consolidated_data.drop(labels=number0.index,axis=1)
print(consolidated_data.shape)
consolidated_data.head()
consolidated_data.insert(loc=1,column="Cp",value=Cp)

# 删除低方差的值
var_data = consolidated_data.iloc[:,2:].var()
del_col = var_data[var_data<0.1].index
consolidated_data = consolidated_data.drop(labels=del_col,axis=1)
print(consolidated_data.shape)
consolidated_data.head()

# 删除重复值多的列
Duplicated_series=pd.Series(np.zeros(len(consolidated_data.columns)))
Duplicated_series.index = consolidated_data.columns.values
for i in consolidated_data.columns:
    Duplicated_series[i] = len(Counter(consolidated_data[i]))
    
Duplicated_series = Duplicated_series.sort_values(0)    
# Duplicated_series60 = Duplicated_series[Duplicated_series>60]    
Duplicated_series15 = Duplicated_series[Duplicated_series<=final_data.shape[0]/10]
consolidated_data = consolidated_data.drop(labels=Duplicated_series15.index,axis=1)
print(consolidated_data.shape)
consolidated_data.head()
correlation = consolidated_data.iloc[:,1:].corr('spearman')
correlation
df_bool = (abs(correlation) > 0.85)
correlation[df_bool]
DN_correlation = consolidated_data.iloc[:,1:].corr('spearman')["Cp"]
DN_correlation[DN_correlation>0.1]

bb = []
col_index = correlation.index
for i in range(0,len(col_index)):
    for j in range(i+1,len(col_index)):
        bb.append([col_index[i],col_index[j]])
k = 0
del_list = []
for i in bb:
    if not math.isnan(correlation[df_bool].loc[i[0],i[1]]) and ('Cp'not in i):
        k+=1
        if abs(DN_correlation[i[0]])>abs(DN_correlation[i[1]]):
            if i[1] not in del_list:
                del_list.append(i[1])
        else:
            if i[0] not in del_list:
                del_list.append(i[0])
            
print(del_list)
k 
Test_data = consolidated_data.drop(labels=del_list,axis=1)
Test_data
Test_data.to_excel("Cp-descriptor75.xlsx")
